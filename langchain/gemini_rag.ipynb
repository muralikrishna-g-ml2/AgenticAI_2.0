{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2116a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['GEMINI_API_KEY']=os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2613d21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
    "\tmodel=\"models/embedding-001\",\n",
    "\tgoogle_api_key=os.environ['GEMINI_API_KEY']\n",
    ")\n",
    "\n",
    "embeddings=embeddings_model.embed_query(\"Hello world\")  # Example query\n",
    "len(embeddings)\n",
    "\n",
    "# embeddings = embeddings_model.embed_documents([\"Hello world\", \"Goodbye world\"])\n",
    "# print(embeddings)\n",
    "# len(embeddings)  # Should print 2, as we have two documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c4345fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54779149 0.63220972 0.75589552]]\n",
      "The most similar document is at index: 2\n",
      "The most similar document is: Who is a prime minister of India?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "documents=[\"what is a capital of USA?\",\n",
    "           \"Who is a president of USA?\",\n",
    "           \"Who is a prime minister of India?\"]\n",
    "document_embedding = embeddings_model.embed_documents(documents)\n",
    "\n",
    "my_query = \"Narendra modi is prime minister of india?\"\n",
    "query_embedding = embeddings_model.embed_query(my_query)\n",
    "\n",
    "# Calculate cosine similarity between the query embedding and each document embedding\n",
    "similarities = cosine_similarity([query_embedding], document_embedding)\n",
    "print(similarities)\n",
    "# To get the similarity score for each document with respect to the query\n",
    "similarities[0]  # This will give you the similarity scores for each document with respect to the query\n",
    "# To get the index of the most similar document\n",
    "most_similar_index = similarities[0].argmax()\n",
    "print(f\"The most similar document is at index: {most_similar_index}\")\n",
    "# To get the most similar document\n",
    "most_similar_document = documents[most_similar_index]\n",
    "print(f\"The most similar document is: {most_similar_document}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c80da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95100778 0.8576593  0.698719  ]]\n",
      "The closest document is at index: 2\n",
      "The closest document is: Who is a prime minister of India?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# Calculate Euclidean distances between the query embedding and each document embedding\n",
    "euclidean_distances_result = euclidean_distances([query_embedding], document_embedding)\n",
    "print(euclidean_distances_result)\n",
    "# To get the distance for each document with respect to the query\n",
    "euclidean_distances_result[0]  # This will give you the distances for each document with respect to the query   \n",
    "# To get the index of the closest document\n",
    "closest_index = euclidean_distances_result[0].argmin()\n",
    "print(f\"The closest document is at index: {closest_index}\")\n",
    "# To get the closest document\n",
    "closest_document = documents[closest_index]\n",
    "print(f\"The closest document is: {closest_document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a30390",
   "metadata": {},
   "source": [
    "| Metric            | Similarity Score Range | Behavior                              |\n",
    "| ----------------- | ---------------------- | ------------------------------------- |\n",
    "| Cosine Similarity | \\[-1, 1]               | Focuses on angle only |\n",
    "| L2 Distance       | \\[0, âˆž)                | Focuses on **magnitude + direction**  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2664b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities: [0.4735272  0.51139907 0.76754131 0.46933159]\n",
      "Euclidean Distances: [1.02613069 0.98853459 0.68184802 1.03021138]\n",
      "Most similar (cosine): 'The capital of France is Paris.'\n",
      "Closest (L2): 'The capital of France is Paris.'\n"
     ]
    }
   ],
   "source": [
    "# Additional examples to illustrate similarity metrics\n",
    "\n",
    "# New set of documents and a query\n",
    "more_documents = [\n",
    "    \"The sun rises in the east.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Dogs are loyal animals.\"\n",
    "]\n",
    "more_query = \"What is the capital city of France?\"\n",
    "\n",
    "# Get embeddings for new documents and query\n",
    "more_doc_embeddings = embeddings_model.embed_documents(more_documents)\n",
    "more_query_embedding = embeddings_model.embed_query(more_query)\n",
    "\n",
    "# Cosine similarity\n",
    "cos_sim = cosine_similarity([more_query_embedding], more_doc_embeddings)\n",
    "print(\"Cosine Similarities:\", cos_sim[0])\n",
    "\n",
    "# Euclidean (L2) distance\n",
    "l2_dist = euclidean_distances([more_query_embedding], more_doc_embeddings)\n",
    "print(\"Euclidean Distances:\", l2_dist[0])\n",
    "\n",
    "# Find most similar document by cosine similarity\n",
    "most_sim_cos_idx = cos_sim[0].argmax()\n",
    "print(f\"Most similar (cosine): '{more_documents[most_sim_cos_idx]}'\")\n",
    "\n",
    "# Find closest document by Euclidean distance\n",
    "closest_l2_idx = l2_dist[0].argmin()\n",
    "print(f\"Closest (L2): '{more_documents[closest_l2_idx]}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8e178fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity:\n",
      "  Pros:\n",
      "    - Measures the angle between vectors, focusing on their direction (semantic meaning).\n",
      "    - Ignores the magnitude, so it's robust to differences in document/query length or scale.\n",
      "    - Well-suited for text similarity tasks where the length of text varies.\n",
      "  Cons:\n",
      "    - Ignores magnitude, so it may miss important differences if vector length carries meaning.\n",
      "\n",
      "L2 (Euclidean) Distance:\n",
      "  Pros:\n",
      "    - Considers both the direction and magnitude of vectors.\n",
      "    - Useful when absolute values or the scale of embeddings are important.\n",
      "  Cons:\n",
      "    - Sensitive to the length and scale of vectors, which can be affected by document/query length.\n",
      "    - May not reflect semantic similarity if magnitude is not meaningful in the context.\n",
      "\n",
      "Example 1: Same direction, different magnitude\n",
      "Cosine similarity: 1.00 (should be 1.0)\n",
      "L2 (Euclidean) distance: 3.74 (should be > 0)\n",
      "\n",
      "Example 2: Large magnitude difference\n",
      "Cosine similarity: 1.00 (should be 1.0)\n",
      "L2 (Euclidean) distance: 370.42 (should be large)\n",
      "\n",
      "Example 3: Opposite direction, same magnitude\n",
      "Cosine similarity: -1.00 (should be -1.0)\n",
      "L2 (Euclidean) distance: 7.48 (should be large)\n",
      "\n",
      "Example 4: Text embeddings (semantic similarity)\n",
      "Cosine similarity between query and most similar document: 0.76\n",
      "L2 distance between query and closest document: 0.70\n",
      "Most similar document (cosine): 'Who is a prime minister of India?'\n",
      "Closest document (L2): 'Who is a prime minister of India?'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Clear explanation of pros and cons\n",
    "print(\"\\nCosine Similarity:\")\n",
    "print(\"  Pros:\")\n",
    "print(\"    - Measures the angle between vectors, focusing on their direction (semantic meaning).\")\n",
    "print(\"    - Ignores the magnitude, so it's robust to differences in document/query length or scale.\")\n",
    "print(\"    - Well-suited for text similarity tasks where the length of text varies.\")\n",
    "print(\"  Cons:\")\n",
    "print(\"    - Ignores magnitude, so it may miss important differences if vector length carries meaning.\")\n",
    "\n",
    "print(\"\\nL2 (Euclidean) Distance:\")\n",
    "print(\"  Pros:\")\n",
    "print(\"    - Considers both the direction and magnitude of vectors.\")\n",
    "print(\"    - Useful when absolute values or the scale of embeddings are important.\")\n",
    "print(\"  Cons:\")\n",
    "print(\"    - Sensitive to the length and scale of vectors, which can be affected by document/query length.\")\n",
    "print(\"    - May not reflect semantic similarity if magnitude is not meaningful in the context.\")\n",
    "\n",
    "\n",
    "# Example 1: Cosine similarity ignores magnitude (length)\n",
    "vec_a = [1, 2, 3]\n",
    "vec_b = [2, 4, 6]  # Same direction as vec_a, but twice the magnitude\n",
    "\n",
    "cos_sim_example = cosine_similarity([vec_a], [vec_b])[0][0]\n",
    "l2_dist_example = euclidean_distances([vec_a], [vec_b])[0][0]\n",
    "\n",
    "print(\"\\nExample 1: Same direction, different magnitude\")\n",
    "print(f\"Cosine similarity: {cos_sim_example:.2f} (should be 1.0)\")\n",
    "print(f\"L2 (Euclidean) distance: {l2_dist_example:.2f} (should be > 0)\")\n",
    "\n",
    "# Example 2: L2 distance sensitive to scale\n",
    "vec_c = [100, 200, 300]\n",
    "cos_sim_example2 = cosine_similarity([vec_a], [vec_c])[0][0]\n",
    "l2_dist_example2 = euclidean_distances([vec_a], [vec_c])[0][0]\n",
    "\n",
    "print(\"\\nExample 2: Large magnitude difference\")\n",
    "print(f\"Cosine similarity: {cos_sim_example2:.2f} (should be 1.0)\")\n",
    "print(f\"L2 (Euclidean) distance: {l2_dist_example2:.2f} (should be large)\")\n",
    "\n",
    "# Example 3: Different direction, same magnitude\n",
    "vec_d = [-1, -2, -3]\n",
    "cos_sim_example3 = cosine_similarity([vec_a], [vec_d])[0][0]\n",
    "l2_dist_example3 = euclidean_distances([vec_a], [vec_d])[0][0]\n",
    "\n",
    "print(\"\\nExample 3: Opposite direction, same magnitude\")\n",
    "print(f\"Cosine similarity: {cos_sim_example3:.2f} (should be -1.0)\")\n",
    "print(f\"L2 (Euclidean) distance: {l2_dist_example3:.2f} (should be large)\")\n",
    "\n",
    "# Example 4: Text embeddings (semantic similarity)\n",
    "print(\"\\nExample 4: Text embeddings (semantic similarity)\")\n",
    "print(f\"Cosine similarity between query and most similar document: {similarities[0][most_similar_index]:.2f}\")\n",
    "print(f\"L2 distance between query and closest document: {euclidean_distances_result[0][closest_index]:.2f}\")\n",
    "print(f\"Most similar document (cosine): '{most_similar_document}'\")\n",
    "print(f\"Closest document (L2): '{closest_document}'\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b67254fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1: 'The quick brown fox jumps over the lazy dog.'\n",
      "Cosine similarity: 0.84\n",
      "L2 (Euclidean) distance: 0.57\n",
      "\n",
      "Example 2: 'The quick brown fox jumps over the lazy dog.'\n",
      "Cosine similarity: 0.84\n",
      "L2 (Euclidean) distance: 0.57\n",
      "\n",
      "Example 3: 'The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.'\n",
      "Cosine similarity: 0.83\n",
      "L2 (Euclidean) distance: 0.58\n",
      "\n",
      "Example 4: 'Completely unrelated sentence about machine learning.'\n",
      "Cosine similarity: 0.56\n",
      "L2 (Euclidean) distance: 0.94\n",
      "\n",
      "Interpretation:\n",
      "- Example 1 & 2: Identical sentences â€” cosine similarity = 1, L2 distance = 0.\n",
      "- Example 3: Same sentence repeated â€” cosine similarity â‰ˆ 1 (same direction), L2 distance increases (greater magnitude).\n",
      "- Example 4: Unrelated sentence â€” cosine similarity low, L2 distance high.\n"
     ]
    }
   ],
   "source": [
    "# Refined examples to clearly illustrate cosine similarity vs L2 distance\n",
    "\n",
    "example_texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",  # Reference\n",
    "    \"The quick brown fox jumps over the lazy dog.\",  # Identical\n",
    "    \"The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\",  # Same direction, double length\n",
    "    \"Completely unrelated sentence about machine learning.\"  # Different topic\n",
    "]\n",
    "\n",
    "# Get embeddings for the example texts\n",
    "example_text_embeddings = embeddings_model.embed_documents(example_texts)\n",
    "\n",
    "# Use the first sentence as the query\n",
    "example_query_text = example_texts[0]\n",
    "example_query_text_embedding = embeddings_model.embed_query(example_query_text)\n",
    "\n",
    "# Cosine similarity\n",
    "example_cosine_sim = cosine_similarity([example_query_text_embedding], example_text_embeddings)[0]\n",
    "# L2 distance\n",
    "example_l2_dist = euclidean_distances([example_query_text_embedding], example_text_embeddings)[0]\n",
    "\n",
    "# Display results\n",
    "for i, text in enumerate(example_texts):\n",
    "    print(f\"\\nExample {i+1}: '{text}'\")\n",
    "    print(f\"Cosine similarity: {example_cosine_sim[i]:.2f}\")\n",
    "    print(f\"L2 (Euclidean) distance: {example_l2_dist[i]:.2f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Example 1 & 2: Identical sentences â€” cosine similarity = 1, L2 distance = 0.\")\n",
    "print(\"- Example 3: Same sentence repeated â€” cosine similarity â‰ˆ 1 (same direction), L2 distance increases (greater magnitude).\")\n",
    "print(\"- Example 4: Unrelated sentence â€” cosine similarity low, L2 distance high.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91854a38",
   "metadata": {},
   "source": [
    "## Using more advanced similarity searches using vector stores\n",
    "\n",
    "### Local In Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "589bd375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FAISS Similarity Search Results (with scores):\n",
      "Query: Narendra modi is prime minister of india?, Document: Who is a prime minister of India?, Score: 0.48820820450782776\n",
      "Query: Narendra modi is prime minister of india?, Document: Who is a president of USA?, Score: 0.7355794906616211\n",
      "Query: Narendra modi is prime minister of india?, Document: what is a capital of USA?, Score: 0.9044157266616821\n",
      "\n",
      "FAISS Similarity Search Results for New Query (with scores):\n",
      "Query: What is the capital of the USA?, Document: what is a capital of USA?, Score: 0.3721003234386444\n",
      "Query: What is the capital of the USA?, Document: Who is a president of USA?, Score: 0.5979712009429932\n",
      "Query: What is the capital of the USA?, Document: Who is a prime minister of India?, Score: 0.8431156873703003\n",
      "\n",
      "Loaded FAISS Similarity Search Results (with scores):\n",
      "Query: Narendra modi is prime minister of india?, Document: Who is a prime minister of India?, Score: 0.48820820450782776\n",
      "Query: Narendra modi is prime minister of india?, Document: Who is a president of USA?, Score: 0.7355794906616211\n",
      "Query: Narendra modi is prime minister of india?, Document: what is a capital of USA?, Score: 0.9044157266616821\n",
      "\n",
      "Loaded FAISS Similarity Search Results for New Query (with scores):\n",
      "Query: What is the capital of the USA?, Document: what is a capital of USA?, Score: 0.3721003234386444\n",
      "Query: What is the capital of the USA?, Document: Who is a president of USA?, Score: 0.5979712009429932\n",
      "Query: What is the capital of the USA?, Document: Who is a prime minister of India?, Score: 0.8431156873703003\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# create embeddings model\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
    "\tmodel=\"models/embedding-001\",\n",
    "\tgoogle_api_key=os.environ['GEMINI_API_KEY']\n",
    ")\n",
    "\n",
    "# Data set 1\n",
    "documents=[\"what is a capital of USA?\",\n",
    "           \"Who is a president of USA?\",\n",
    "           \"Who is a prime minister of India?\"]\n",
    "document_embedding = embeddings_model.embed_documents(documents)\n",
    "\n",
    "# Step 1: Create an index for FAISS\n",
    "index=faiss.IndexFlatL2(768) # 768 is the dimension of the embeddings\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Add the document embeddings to the index\n",
    "index.add(np.array(document_embedding, dtype=np.float32))  # Add the document embeddings to the index\n",
    "\n",
    "# Step 3: Create a FAISS vector store\n",
    "index_to_docstore_id = {i: i for i in range(len(documents))}\n",
    "docstore_dict = {i: Document(page_content=doc, metadata={\"id\": i}) for i, doc in enumerate(documents)}\n",
    "vectorstore = FAISS(\n",
    "    index=index,\n",
    "    embedding_function=embeddings_model,\n",
    "    docstore=InMemoryDocstore(docstore_dict),\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# No need to add documents again, as they are already in the docstore\n",
    "\n",
    "# Step 5: Perform a similarity search with scores\n",
    "my_query = \"Narendra modi is prime minister of india?\"\n",
    "results_with_score = vectorstore.similarity_search_with_score(my_query, k=3)  # Get top 3 similar documents with scores\n",
    "print(\"\\nFAISS Similarity Search Results (with scores):\")\n",
    "for doc, score in results_with_score:\n",
    "    print(f\"Query: {my_query}, Document: {doc.page_content}, Score: {score}\")\n",
    "\n",
    "# Step 6: Perform a similarity search with a different query and show scores\n",
    "new_query = \"What is the capital of the USA?\"\n",
    "new_results_with_score = vectorstore.similarity_search_with_score(new_query, k=3)\n",
    "print(\"\\nFAISS Similarity Search Results for New Query (with scores):\")\n",
    "for doc, score in new_results_with_score:\n",
    "    print(f\"Query: {new_query}, Document: {doc.page_content}, Score: {score}\")\n",
    "\n",
    "# Step 7: Save the FAISS index to disk\n",
    "vectorstore.save_local(\"faiss_index\")  # Save the index to disk\n",
    "\n",
    "# Step 8: Load the FAISS index from disk\n",
    "loaded_vectorstore = FAISS.load_local(\"faiss_index\", embeddings_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Step 9: Perform a similarity search on the loaded index with scores\n",
    "loaded_results_with_score = loaded_vectorstore.similarity_search_with_score(my_query, k=3)\n",
    "print(\"\\nLoaded FAISS Similarity Search Results (with scores):\")\n",
    "for doc, score in loaded_results_with_score:\n",
    "    print(f\"Query: {my_query}, Document: {doc.page_content}, Score: {score}\")\n",
    "\n",
    "# Step 10: Perform a similarity search with a different query on the loaded index and show scores\n",
    "new_loaded_results_with_score = loaded_vectorstore.similarity_search_with_score(new_query, k=3)\n",
    "print(\"\\nLoaded FAISS Similarity Search Results for New Query (with scores):\")\n",
    "for doc, score in new_loaded_results_with_score:\n",
    "    print(f\"Query: {new_query}, Document: {doc.page_content}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4112fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted documents: The capital of the USA is Washington, D.C.\n",
      "The president of the USA is Donald Trump.\n",
      "The prime minister of India is Narendra Modi.\n",
      "The capital of France is Paris.\n",
      "The capital of Japan is Tokyo.\n",
      "The capital of India is New Delhi.\n",
      "The prime minister of India is Narendra Modi.\n",
      "Narendra Modi is the prime minister of India.\n",
      "The capital of the UK is London.\n",
      "The capital of Germany is Berlin.\n",
      "The capital of Canada is Ottawa.\n",
      "The capital of Australia is Canberra.\n",
      "The capital of Russia is Moscow.\n",
      "The capital of China is Beijing.\n",
      "The capital of Brazil is BrasÃ­lia.\n",
      "The capital of South Africa is Pretoria.\n",
      "The capital of Italy is Rome.\n",
      "The capital of Spain is Madrid.\n",
      "The capital of Mexico is Mexico City.\n",
      "The capital of Argentina is Buenos Aires.\n",
      "\n",
      "-----------------------------------------------\n",
      "Result: The current president of the USA is Joe Biden.  He assumed office on January 20, 2021.\n",
      "Result: The capital of the USA is Washington, D.C.  It's located on the Potomac River.  This city serves as the seat of the U.S. federal government.\n",
      "Result: The capital of France is Paris.  It's a major European city and a global center for art, fashion, gastronomy, and culture.\n",
      "Result: The capital of Japan is Tokyo.  It's located on the southeastern coast of Honshu.  This major city serves as the country's political and economic center.\n",
      "Result: The capital of India is New Delhi.  It's located in northern India and serves as the country's seat of government.\n",
      "Result: The provided context does not contain the answer to who the prime minister of India is.  Therefore, I don't know.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['GEMINI_API_KEY']=os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Create a prompt template for the question-answering task\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\", api_key=os.environ['LANGCHAIN_API_KEY'])\n",
    "\n",
    "# define the model for question-answering\n",
    "model = ChatGoogleGenerativeAI(\n",
    "\tmodel='gemini-1.5-flash',\n",
    "\tgoogle_api_key=os.environ['GEMINI_API_KEY']\n",
    ")\n",
    "\n",
    "# create embeddings model\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
    "\tmodel=\"models/embedding-001\",\n",
    "\tgoogle_api_key=os.environ['GEMINI_API_KEY']\n",
    ")\n",
    "\n",
    "# Create an index for FAISS\n",
    "index=faiss.IndexFlatL2(768) # 768 is the dimension of the embeddings\n",
    "\n",
    "# Create a FAISS vector store\n",
    "vectorstore = FAISS(\n",
    "    index=index,\n",
    "    embedding_function=embeddings_model,\n",
    "    docstore=InMemoryDocstore({}),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3} #hyperparameter\n",
    ")\n",
    "\n",
    "# ------------------------------------ #\n",
    "\n",
    "\n",
    "docs = [\n",
    "        Document(page_content=\"The capital of the USA is Washington, D.C.\"),\n",
    "        Document(page_content=\"The president of the USA is Donald Trump.\"),\n",
    "        Document(page_content=\"The prime minister of India is Narendra Modi.\"),\n",
    "        Document(page_content=\"The capital of France is Paris.\"),\n",
    "        Document(page_content=\"The capital of Japan is Tokyo.\"),\n",
    "        Document(page_content=\"The capital of India is New Delhi.\"),\n",
    "        Document(page_content=\"The prime minister of India is Narendra Modi.\"),\n",
    "        Document(page_content=\"Narendra Modi is the prime minister of India.\"),\n",
    "        Document(page_content=\"The capital of the UK is London.\"),\n",
    "        Document(page_content=\"The capital of Germany is Berlin.\"),\n",
    "        Document(page_content=\"The capital of Canada is Ottawa.\"),\n",
    "        Document(page_content=\"The capital of Australia is Canberra.\"),\n",
    "        Document(page_content=\"The capital of Russia is Moscow.\"),\n",
    "        Document(page_content=\"The capital of China is Beijing.\"),\n",
    "        Document(page_content=\"The capital of Brazil is BrasÃ­lia.\"),\n",
    "        Document(page_content=\"The capital of South Africa is Pretoria.\"),\n",
    "        Document(page_content=\"The capital of Italy is Rome.\"),\n",
    "        Document(page_content=\"The capital of Spain is Madrid.\"),\n",
    "        Document(page_content=\"The capital of Mexico is Mexico City.\"),\n",
    "        Document(page_content=\"The capital of Argentina is Buenos Aires.\"),\n",
    "    ] \n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "print(f\"Formatted documents: {format_docs(docs)}\")  # Print the formatted documents for debugging\n",
    "print()\n",
    "print(\"-----------------------------------------------\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | (lambda docs: format_docs(docs)), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = rag_chain.invoke(\"Who is the president of the USA?\")  # Example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task\n",
    "\n",
    "result = rag_chain.invoke(\"What is the capital of the USA?\")  # Another example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task\n",
    "\n",
    "result = rag_chain.invoke(\"What is the capital of France?\")  # Another example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task\n",
    "\n",
    "result = rag_chain.invoke(\"What is the capital of Japan?\")  # Another example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task\n",
    "\n",
    "result = rag_chain.invoke(\"What is the capital of India?\")  # Another example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task\n",
    "\n",
    "result = rag_chain.invoke(\"Who is the prime minister of India?\")  # Another example question\n",
    "print(f\"Result: {result}\")  # Print the result of the question-answering task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
